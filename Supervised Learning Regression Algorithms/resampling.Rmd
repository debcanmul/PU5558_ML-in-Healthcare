---
title: "resampling"
author: "DBlana"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this worksheet, as before, we will use the same dataset and attempt to predict the variable "DEPRESS" from income and employment rate, CIF, EMERG, attendance, and SIMD health domain rank. We will again use linear regression and random forest modelling, but we will evaluate the performance entirely using the training dataset, using cross validation and bootstrap resampling.

The first steps are the same as before, add the required code in the code chunks provided: 

## Load packages

```{r}


```

## Load data


```{r}


```

## Data splitting


```{r}


```

## Selection and preprocessing of predictors

```{r}


```

## Model specification

Make sure you specify two different models:

```{r}

# Linear regression model specification: lm_spec


# Random forest model specification: rf_spec


```

## Workflow

And two different workflows:

```{r specify-workflow}

# Linear model workflow: DZ_wflow_lm


# Random forest workflow: DZ_wflow_rf


```


## Model training and evaluation with resampling

Using resampling, we can evaluate the modelling process (including the choice of model, selection of predictors, pre-processing steps, hyperparameter values) without touching the testing dataset.

We have already seen a variety of resampling methods: https://www.tmwr.org/resampling.html#resampling-methods

Here we will use 10-fold cross validation, and bootstraping.

### Cross validation

Cross validation randomly partitions the training data set into V sets of roughly equal size. Here we use V = 10 for ten-fold cross validation. Read more here: https://www.tmwr.org/resampling.html#cv

```{r cross-validation}

DZ_folds <- vfold_cv(DZ_train, v = 10) # 10-fold cross validation

# We want to save the predictions
keep_pred <- control_resamples(save_pred = TRUE)

# Fit the two model:

# Linear regression (make sure you named the workflow DZ_wflow_lm)
DZ_wflow_lm_fit <- DZ_wflow_lm %>%
    fit_resamples(resamples = DZ_folds, 
                  control = keep_pred)

# Random forest (make sure you named the workflow DZ_wflow_rf)
DZ_wflow_rf_fit <- DZ_wflow_rf %>%
    fit_resamples(resamples = DZ_folds, 
                  control = keep_pred)
    
```

The default performance metrics here are RMSE and R squared:

```{r cross-val-performance}

bind_rows(collect_metrics(DZ_wflow_lm_fit) %>%
                          mutate(model = "linear_regression"),
          collect_metrics(DZ_wflow_rf_fit) %>%
                          mutate(model = "random_forest"))

```

If you compare to the previous worksheets, even though we are using the training dataset, the performance is much closer to the testing dataset results!

Let's also collect and plot the predictions:

```{r cross-val-plot}

results <-  bind_rows(DZ_wflow_lm_fit %>%
                          collect_predictions() %>%
                          mutate(model = "linear_regression") %>%
                          rename(pred_DEPRESS = .pred),
                      DZ_wflow_rf_fit %>%
                          collect_predictions() %>%
                          mutate(model = "random_forest") %>%
                          rename(pred_DEPRESS = .pred))

results %>%
    ggplot(aes(x = DEPRESS, y = pred_DEPRESS)) +
    geom_abline(intercept=0, slope=1) +  # we want data to fall close to this line
    geom_point() +
    facet_wrap(~ model)

```

### Bootstrap

Bootstrap resampling creates new samples of the same size as the training set, drawn with replacement from the training set: https://www.tmwr.org/resampling.html#bootstrap 

```{r bootstrap}

DZ_boot <- bootstraps(DZ_train, times=5)  # we want five bootstrap samples

# We want to save the predictions
keep_pred <- control_resamples(save_pred = TRUE)

# Fit the model
DZ_wflow_lm_fit <- DZ_wflow_lm %>%
    fit_resamples(resamples = DZ_boot, 
                  control = keep_pred)

DZ_wflow_rf_fit <- DZ_wflow_rf %>%
    fit_resamples(resamples = DZ_boot, 
                  control = keep_pred)
    
```

Let's look at the performance metrics:

```{r bootstrap-performance}

bind_rows(collect_metrics(DZ_wflow_lm_fit) %>%
                          mutate(model = "linear_regression"),
          collect_metrics(DZ_wflow_rf_fit) %>%
                          mutate(model = "random_forest"))

```

Let's also collect and plot the predictions:

```{r boostrap-plot}

# For bootstrap, when we run collect_predictions, there are multiple predictions per row of the original training set.
# We use summarize = TRUE to obtain summarized values (averages of the replicate predictions) 

results <-  bind_rows(DZ_wflow_lm_fit %>%
                          collect_predictions(summarize = TRUE) %>%
                          mutate(model = "linear_regression") %>%
                          rename(pred_DEPRESS = .pred),
                      DZ_wflow_rf_fit %>%
                          collect_predictions(summarize = TRUE) %>%
                          mutate(model = "random_forest") %>%
                          rename(pred_DEPRESS = .pred))

results %>%
    ggplot(aes(x = DEPRESS, y = pred_DEPRESS)) +
    geom_abline(intercept=0, slope=1) +  # we want data to fall close to this line
    geom_point() +
    facet_wrap(~ model)

```

This process would allow us to select our final model. Remember that this does not only mean choosing between linear regression or random forest, but also the optimal values of hyperparameters (if our model contains any). We could also have used resampling on the training dataset to evaluate different sets of predictors, and different pre-processing steps - although we didn't do this here (you are welcome to try it!) 

When we have chosen our final model, we would then (and only then!) evaluate it on our testing dataset.

We can do this using fit() on our training set and predict() on our testing set, as we saw previously, or we could use final_fit() on the data split object, which fits on the training data and evaluates on the testing data in one step: 

```{r final-fit}

# Fit the two models (make sure you named the data split object DZ_split)

DZ_wflow_lm_finalfit <- DZ_wflow_lm %>%
    last_fit(DZ_split)

DZ_wflow_rf_finalfit <- DZ_wflow_rf %>%
    last_fit(DZ_split)

# Print performance metrics on testing data
bind_rows(collect_metrics(DZ_wflow_lm_finalfit) %>%
                          mutate(model = "linear_regression"),
          collect_metrics(DZ_wflow_rf_finalfit) %>%
                          mutate(model = "random_forest"))

```


## Practice

Compare linear regression and random forest modelling:

1. In the same dataset for different predictors, or a different outcome, and for different values of the random forest hyperparameters.  

2. In the body fat dataset.


